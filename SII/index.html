<head>
    <title>SII Projects</title>
    <meta name="keywords" content="Hongyang Li, Autonomous Driving, Embodied AI">

    <link rel="icon" type="image/png" href="/content/hku-64.png">

    <link href="/css/index_tailwind.css" rel="stylesheet">
</head>



<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-7CV6WH2D39"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-7CV6WH2D39');
</script>



<body class="h-fit flex justify-center">
    <div class="h-fit w-full laptop:w-288 p-6 laptop:p-10 pt-24 pb-24 laptop:pt-24 laptop:pb-24">
        




        <div class="flex flex-col gap-6">

            <p>
                2025年在我们为大家准备了丰富多样的课题方向，欢迎各位前来了解，开启你的精彩研究之路！
            </p>
        
        </div>



        <div class="mt-20 flex flex-col gap-6">

            <h2 class="text-o-dark-blue">
                [AD01] World Model / Reward Model for Planning
            </h2>

            <ul class="ml-6 space-y-2 list-outside list-disc">
                <li>课题介绍：探究 world model 如何服务于 planning 任务。基于 Model-based 范式，学会当前状态当前动作→下一个状态与价值的映射关系，学习 reward model，包含对驾驶场景的理解与行为评估，从而实现可预测的轨迹生成与策略学习。</li>
                <li>课题导师：李弘扬（<a class="text-o-blue hover:text-o-hover" href="https://lihongyang.info/" target="_blank">lihongyang.info</a> / <a class="text-o-blue hover:text-o-hover" href="https://opendrivelab.com/" target="_blank">opendrivelab.com</a>）、张力（<a class="text-o-blue hover:text-o-hover" href="https://lzrobots.github.io/" target="_blank">lzrobots.github.io</a>）</li>
            </ul>

        </div>



        <div class="mt-20 flex flex-col gap-6">

            <h2 class="text-o-dark-blue">
                [AD02] Scalable RL for Planning
            </h2>

            <ul class="ml-6 space-y-2 list-outside list-disc">
                <li>课题介绍：Scalable RL for Planning 聚焦强化学习在高维、高交互、长时序自动驾驶规划任务中的扩展性问题。模仿学习范式需要海量高质量数据拟合，且存在分布偏移，因果混淆等问题；强化学习范式在应用于大规模自动驾驶规划中，面临泛化性与稳定性挑战。探索包括多智能体强化学习（Multi-agent RL）、自博弈（Self-play）、模仿 + 强化联合微调（IL+RL Finetuning）等方向，实现具备通用性与泛化能力的规划策略。</li>
                <li>课题导师：李弘扬（<a class="text-o-blue hover:text-o-hover" href="https://lihongyang.info/" target="_blank">lihongyang.info</a> / <a class="text-o-blue hover:text-o-hover" href="https://opendrivelab.com/" target="_blank">opendrivelab.com</a>）、张力（<a class="text-o-blue hover:text-o-hover" href="https://lzrobots.github.io/" target="_blank">lzrobots.github.io</a>）</li>
            </ul>

        </div>



        <div class="mt-20 flex flex-col gap-6">

            <h2 class="text-o-dark-blue">
                [AD03] VLA with Latent Feature: Reducing Dependence on High-Quality Labels
            </h2>

            <ul class="ml-6 space-y-2 list-outside list-disc">
                <li>课题介绍：探究如何降低端到端训练对地图与 bounding box 的标注依赖。利用大规模无标注驾驶视频，进行潜在特征学习。通过在潜在空间中对视频表征与规划轨迹进行融合，构建具备语义理解与未来预测能力的视觉 - 规划联合模型。</li>
                <li>课题导师：李弘扬（<a class="text-o-blue hover:text-o-hover" href="https://lihongyang.info/" target="_blank">lihongyang.info</a> / <a class="text-o-blue hover:text-o-hover" href="https://opendrivelab.com/" target="_blank">opendrivelab.com</a>）、张力（<a class="text-o-blue hover:text-o-hover" href="https://lzrobots.github.io/" target="_blank">lzrobots.github.io</a>）</li>
            </ul>

        </div>



        <div class="mt-20 flex flex-col gap-6">

            <h2 class="text-o-dark-blue">
                [AD04] 大规模场景重建与物理引擎
            </h2>

            <ul class="ml-6 space-y-2 list-outside list-disc">
                <li>课题介绍：实现真实交通场景在任意视角下的高保 真还原，集成物理引擎以支持车辆、行 人与环境间的真实交互，为自动驾驶的 训练、评估与决策生成提供具备泛化能 力与高一致性的基础环境支撑。</li>
                <li>课题导师：李弘扬（<a class="text-o-blue hover:text-o-hover" href="https://lihongyang.info/" target="_blank">lihongyang.info</a> / <a class="text-o-blue hover:text-o-hover" href="https://opendrivelab.com/" target="_blank">opendrivelab.com</a>）、张力（<a class="text-o-blue hover:text-o-hover" href="https://lzrobots.github.io/" target="_blank">lzrobots.github.io</a>）</li>
            </ul>

        </div>



        <div class="mt-20 flex flex-col gap-6">

            <h2 class="text-o-dark-blue">
                [AD05] City-scale AD Reconstruction
            </h2>

            <ul class="ml-6 space-y-2 list-outside list-disc">
                <li>课题介绍：搭建城市级大规模 3DGS 场景，基于多趟车载激光雷达与相机数据，解决数据间光照和天气等差异性问题。同步开发高效自动化工具链，实现资产360度稀疏视角重建，物体插入、编辑与评测，攻克插入真实感、阴影等细节，为下游任务提供服务。</li>
                <li>课题导师：李弘扬（<a class="text-o-blue hover:text-o-hover" href="https://lihongyang.info/" target="_blank">lihongyang.info</a> / <a class="text-o-blue hover:text-o-hover" href="https://opendrivelab.com/" target="_blank">opendrivelab.com</a>）、张力（<a class="text-o-blue hover:text-o-hover" href="https://lzrobots.github.io/" target="_blank">lzrobots.github.io</a>）</li>
            </ul>

        </div>



        <div class="mt-20 flex flex-col gap-6">

            <h2 class="text-o-dark-blue">
                [AD06] Multi-Modal Video/Lidar Generation
            </h2>

            <ul class="ml-6 space-y-2 list-outside list-disc">
                <li>课题介绍：致力于探究多模态，交互可控的自动驾驶传感器数据合成范式，实现多模态联合的可控生成，结合视频、点云、物体轨迹等模态数据，可控且精确的生成场景中前景的运动，包含BEV视角等多模态视角的输出，构造更多可交互的场景合成。</li>
                <li>课题导师：李弘扬（<a class="text-o-blue hover:text-o-hover" href="https://lihongyang.info/" target="_blank">lihongyang.info</a> / <a class="text-o-blue hover:text-o-hover" href="https://opendrivelab.com/" target="_blank">opendrivelab.com</a>）、张力（<a class="text-o-blue hover:text-o-hover" href="https://lzrobots.github.io/" target="_blank">lzrobots.github.io</a>）</li>
            </ul>

        </div>



        <div class="mt-20 flex flex-col gap-6">

            <h2 class="text-o-dark-blue">
                [AD07] Simulation / Benchmarking for VLA
            </h2>

            <ul class="ml-6 space-y-2 list-outside list-disc">
                <li>课题介绍：构建面向 VLA 的评测体系。现阶段 VLA 模型采用学术界 benchmark 如 nuPlan/nuScense，场景简单无法体现模型在复杂交通场景中 cot 推理与决策能力。构建面向 VLA 的高保真评测体系，生成高价值场景，如施工，交通标识，潮汐车道等，全面评测 VLA 模型性能。</li>
                <li>课题导师：李弘扬（<a class="text-o-blue hover:text-o-hover" href="https://lihongyang.info/" target="_blank">lihongyang.info</a> / <a class="text-o-blue hover:text-o-hover" href="https://opendrivelab.com/" target="_blank">opendrivelab.com</a>）、张力（<a class="text-o-blue hover:text-o-hover" href="https://lzrobots.github.io/" target="_blank">lzrobots.github.io</a>）</li>
            </ul>

        </div>


        
        <div class="mt-20 flex flex-col gap-6">

            <h2 class="text-o-blue">
                [Embodied01] 自动复位构建自动化评测流程
            </h2>

            <ul class="ml-6 space-y-2 list-outside list-disc">
                <li>课题介绍：</li>
                <ul class="ml-6 space-y-2 list-outside list-disc">
                    <li>目的：低成本达到真机评测效果，评测结果可复现，设计评测任务应该是正向推理难，反向恢复简单的。</li>
                    <li>做法：参考AutoEval（<a class="text-o-blue hover:text-o-hover" href="https://arxiv.org/pdf/2503.24278" target="_blank">2503.24278</a>），设计自动化管线，加速推理（缓存中间结果）。</li>
                    <li>实现：训练自动复位policy，从指定环境下任意状态出发，将场景回归到任务初始状态</li>
                </ul>                  
                <li>课题导师：卢策吾（<a class="text-o-blue hover:text-o-hover" href="https://www.mvig.org/" target="_blank">mvig.org</a>）、李弘扬（<a class="text-o-blue hover:text-o-hover" href="https://lihongyang.info/" target="_blank">lihongyang.info</a> / <a class="text-o-blue hover:text-o-hover" href="https://opendrivelab.com/" target="_blank">opendrivelab.com</a>）</li>
            </ul>

        </div>



        <div class="mt-20 flex flex-col gap-6">

            <h2 class="text-o-blue">
                [Embodied02] 自视觉语言模型形成多维度评测标准
            </h2>

            <ul class="ml-6 space-y-2 list-outside list-disc">
                <li>课题介绍：</li>
                <ul class="ml-6 space-y-2 list-outside list-disc">
                    <li>目的：VLM评测视频中机械臂的任务完成情况与中间状态，提供partial reward。构建模型能力光谱图，提供错因分析等。</li>
                    <li>做法：参考World Model Evaluator（<a class="text-o-blue hover:text-o-hover" href="https://arxiv.org/pdf/2506.00613" target="_blank">2506.00613</a>），设计鲁棒的VLM评测视频的方法与流程。</li>
                </ul>
                <li>课题导师：卢策吾（<a class="text-o-blue hover:text-o-hover" href="https://www.mvig.org/" target="_blank">mvig.org</a>）、李弘扬（<a class="text-o-blue hover:text-o-hover" href="https://lihongyang.info/" target="_blank">lihongyang.info</a> / <a class="text-o-blue hover:text-o-hover" href="https://opendrivelab.com/" target="_blank">opendrivelab.com</a>）</li>
            </ul>

        </div>



        <div class="mt-20 flex flex-col gap-6">

            <h2 class="text-o-blue">
                [Embodied03] 生成式世界模型打造通用评测管线
            </h2>

            <ul class="ml-6 space-y-2 list-outside list-disc">
                <li>课题介绍：</li>
                <ul class="ml-6 space-y-2 list-outside list-disc">
                    <li>目的：可控视频生成，基于robotics policy的输出action（joint state，eef等）与初始帧，生成基于action演化的多个未来帧。多模态可控视频生成（包含lidar，depth等机器人特有传感数据），生成视频后通过三维视觉技术提取机械臂action做cross verify。</li>
                    <li>做法：参考Enerverse-AC（<a class="text-o-blue hover:text-o-hover" href="https://github.com/AgibotTech/EnerVerse-AC" target="_blank">github.com/AgibotTech/EnerVerse-AC</a>），设计与训练一致性强的action-condition video model。</li>
                </ul>                
                <li>课题导师：卢策吾（<a class="text-o-blue hover:text-o-hover" href="https://www.mvig.org/" target="_blank">mvig.org</a>）、李弘扬（<a class="text-o-blue hover:text-o-hover" href="https://lihongyang.info/" target="_blank">lihongyang.info</a> / <a class="text-o-blue hover:text-o-hover" href="https://opendrivelab.com/" target="_blank">opendrivelab.com</a>）</li>
            </ul>

        </div>



        <div class="mt-20 flex flex-col gap-6">

            <h2 class="text-o-blue">
                [Embodied04] 三维重建真实世界闭环仿真（tentative）
            </h2>

            <ul class="ml-6 space-y-2 list-outside list-disc">
                <li>课题介绍：</li>
                <ul class="ml-6 space-y-2 list-outside list-disc">
                    <li>目的：实现前背景分离的三维重建真实场景，支持机械臂对前景物体的操作与逆动力学场景网格重建。</li>
                    <li>做法：参考roboarena（<a class="text-o-blue hover:text-o-hover" href="https://beam-workshop2025.github.io/" target="_blank">beam-workshop2025.github.io</a>），用三维重建技术如3dgs等重建真实场景，基于此做三维场景编辑等。</li>
                </ul>                
                <li>课题导师：卢策吾（<a class="text-o-blue hover:text-o-hover" href="https://www.mvig.org/" target="_blank">mvig.org</a>）、李弘扬（<a class="text-o-blue hover:text-o-hover" href="https://lihongyang.info/" target="_blank">lihongyang.info</a> / <a class="text-o-blue hover:text-o-hover" href="https://opendrivelab.com/" target="_blank">opendrivelab.com</a>）</li>
            </ul>

        </div>



        <div class="mt-20 flex flex-col gap-6">

            <h2 class="text-o-blue">
                [Embodied05] 零/少样本新技能学习能力评测（tentative）
            </h2>

            <ul class="ml-6 space-y-2 list-outside list-disc">
                <li>课题介绍：</li>
                <ul class="ml-6 space-y-2 list-outside list-disc">
                    <li>目的：评测robotics manipulation policy的“举一反三”能力。模型是否具备自我纠正/学习、自我演进的能力。</li>
                </ul>               
                <li>课题导师：卢策吾（<a class="text-o-blue hover:text-o-hover" href="https://www.mvig.org/" target="_blank">mvig.org</a>）、李弘扬（<a class="text-o-blue hover:text-o-hover" href="https://lihongyang.info/" target="_blank">lihongyang.info</a> / <a class="text-o-blue hover:text-o-hover" href="https://opendrivelab.com/" target="_blank">opendrivelab.com</a>）</li>
            </ul>

        </div>



        <div class="mt-20 flex flex-col gap-6">

            <h2 class="text-o-blue">
                [Embodied06] 多机/人机协作场景设计与评测（tentative）
            </h2>

            <ul class="ml-6 space-y-2 list-outside list-disc">
                <li>课题介绍：多台不同构型的机器人或人机交互场景下，评测机器人manipulation policy是否具备主动感知，主动介入，主动获取完成任务所缺失的关键信息等能力。</li>              
                <li>课题导师：卢策吾（<a class="text-o-blue hover:text-o-hover" href="https://www.mvig.org/" target="_blank">mvig.org</a>）、李弘扬（<a class="text-o-blue hover:text-o-hover" href="https://lihongyang.info/" target="_blank">lihongyang.info</a> / <a class="text-o-blue hover:text-o-hover" href="https://opendrivelab.com/" target="_blank">opendrivelab.com</a>）</li>
            </ul>

        </div>

        

    </div>
</body>
