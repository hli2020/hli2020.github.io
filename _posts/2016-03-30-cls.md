---
layout: post
comments: false
title:  "Scene Classification 101"
excerpt: "We implement a classification system to solve the classical problem in computer vision, a final project that is accompanied with the vision course. Old, antique, out of date features are used to salute to classics in old times before the renaissance of deep learning."
date:   2016-03-30 12:00:00
mathjax: true
---

In this project we are required to implement a system to classify five scenes. We use classic methods with feature extraction of the images in a multi-scale framework (spatial pyramid matching) and then train a SVM classifier. The basic steps include:

- Feature Extraction: dense sampling of SIFT descriptors and many other features (HOG, LBP, GIST, etc). In this project, I use FREAK, SURF, BRISK plus SIFT features.

- Codebook Generation: k-means clustering on subset or all of the feature descriptors to learn the codebook. A reasonable codebook size is about 1,024.

- Image Representation: compute a histogram vector to represent each image in terms of distance frequency with the codebook. The basic method is called descriptor quantization. An important alternative is locality-constrained linear coding (LLC), whichs boosts performance.

- Spatial Pyramid Matching [(paper)](http://www-cvr.ai.uiuc.edu/ponce_grp/publication/paper/cvpr06b.pdf): 
Only local feature description does not have the spatial order of local descriptors, which limits the descriptive power in image representation. Instead we implement a spatial pyramid matching method to consider feature descriptors in different scales (levels). The following figure shows the gist.

<div class="imgcap">
<img src="/assets/cls/spm.png" width="500">
<div class="thecap" style="text-align:justify">Consider a 3-level spaticial pyramid matching. Each level is devided into different grids and we obtain the corresponding image representations within each grid. Then we pool (max, mean or absolute, etc.) these results within each level and concatenate the pooled representations among levels with weights. There are three types of features in this particular example.</div>
</div>

- Classifier Learning: one is linear SVM and its alternative is kernel SVM.


The final result I achieve is %. [Source code]() (written in C++ and tested on Visual Studio 2010) is available for reference. 

#### The Baseline Model

The basic pipeline is `sift -> k-means codebook -> descriptor quntization -> linear SVM`, and achieves around 32% accuracy.


### Tuning Parameters and Adding Upgraded Components

In general, there are some rules of thumb (aka, failure experiences):

- Linear vs kernel SVM: I tried the radius kernel, which is the default setting in OpenCV and it sucks. Maybe it's related to the data patterns (sparse or not, for example) of the descriptors. So linear form will suffice.

- Feature selection: it is of vital importance. Good features are everything. I think this is the main reason why I did not achieve a satisfying result in essence.

- __Memory bottleneck__: the most surprising part during degugging is that the computer 
(16G ROM) keeps telling `insufficient mem alloc in opencv` although I checked the system monitor that the memory didn't be fully occupied at all! So weird. Details: after feature extraction, we have, say `30w x feat_dim` descriptor matrix to compute the codebook using k-means (choosing 1024 from 30w!), the matrix is so large and thus the program crashes. Solution is to reduce the number of descriptors in dense sampling (parameter `max_kps`).

- Misc (minor experiments): Codebook size (1024 vs 1500), the accuracy won't alter much. Pooling method: max is best and others perform way much worse. Coefficients in concatenating representations in SPM: (0.25, 0.25, 0.5) is best. 


To sum up, the contributing parameters used in this project are as follows:

```python
codebookSize = 1024			
imReprest = 2 					# 1 for descriptor quantization, 2 for LLC
useSPM = true
feature = 2						# 1 for sift only, 2 for all
pool_method = 'max'			
svm_type = 'linear'
```

The follwing table shows a summary of the albation study. The first one is the fully-equipped-component version without data augmentation.

<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;border-color:#ccc;}
.tg td{font-family:Arial, sans-serif;font-size:14px;padding:5px 10px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#ccc;color:#333;background-color:#fff;}
.tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:5px 10px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#ccc;color:#333;background-color:#f0f0f0;}
.tg .tg-baqh{text-align:center;vertical-align:top}
.tg .tg-804w{font-family:Arial, Helvetica, sans-serif !important;;text-align:center;vertical-align:top}
</style>

<table class="tg">
  <tr>
    <th class="tg-baqh">Accuracy</th>
    <th class="tg-804w">lab</th>
    <th class="tg-804w">laudry</th>
    <th class="tg-804w">library</th>
    <th class="tg-804w">living room</th>
    <th class="tg-804w">lobby</th>
    <th class="tg-804w">cb_length</th>
    <th class="tg-804w">all_feat</th>
    <th class="tg-804w">LLC_coding</th>
    <th class="tg-804w">SPM</th>
  </tr>
  <tr>
    <td class="tg-baqh"><b>49.5</b></td>
    <td class="tg-804w">25</td>
    <td class="tg-804w">23.5</td>
    <td class="tg-804w">70</td>
    <td class="tg-804w">80</td>
    <td class="tg-804w">40</td>
    <td class="tg-804w">1500</td>
    <td class="tg-804w">yes</td>
    <td class="tg-804w">yes</td>
    <td class="tg-804w">true</td>
  </tr>

    <tr>
    <td class="tg-baqh">49.5</td>
    <td class="tg-804w">40</td>
    <td class="tg-804w">25</td>
    <td class="tg-804w">62.5</td>
    <td class="tg-804w">77.5</td>
    <td class="tg-804w">42.5</td>
    <td class="tg-804w"><font color="green">1024</font></td>
    <td class="tg-804w">yes</td>
    <td class="tg-804w">yes</td>
    <td class="tg-804w">true</td>
  </tr>
    <tr>
    <td class="tg-baqh">47.5</td>
    <td class="tg-804w">40</td>
    <td class="tg-804w">32.5</td>
    <td class="tg-804w">55</td>
    <td class="tg-804w">75</td>
    <td class="tg-804w">35</td>
    <td class="tg-804w">1500</td>
    <td class="tg-804w"><font color="green">onlySIFT</font></td>
    <td class="tg-804w">yes</td>
    <td class="tg-804w">true</td>
  </tr>
    <tr>
    <td class="tg-baqh">33</td>
    <td class="tg-804w">55</td>
    <td class="tg-804w">25</td>
    <td class="tg-804w">50</td>
    <td class="tg-804w">25</td>
    <td class="tg-804w">10</td>
    <td class="tg-804w">1500</td>
    <td class="tg-804w">yes</td>
    <td class="tg-804w"><font color="green">no</font></td>
    <td class="tg-804w">true</td>
  </tr>

      <tr>
    <td class="tg-baqh">44.5</td>
    <td class="tg-804w">22.5</td>
    <td class="tg-804w">30</td>
    <td class="tg-804w">57.5</td>
    <td class="tg-804w">67.5</td>
    <td class="tg-804w">45</td>
    <td class="tg-804w">1500</td>
    <td class="tg-804w">yes</td>
    <td class="tg-804w">yes</td>
    <td class="tg-804w"><font color="green">false</font></td>
  </tr>

</table>


__Results analysis.__ From the results, we can see that the accuracy within each class vaires a lot in each case. Generally, the size of codebook does not matter (within a range). LLC contributes most with more than 10% boost while SPM is also important with 5% increase in accuracy. They did their job, nothing to modify further. However, the contribution from only sift to all hand-crafted features is incremental (only ~2%). Good features are probably the most important factor in the vision community and I propose two solutions to solve this:

- Extract more powerful features: deep learning or other antique features (GIST, LBP, etc). No time or interest to do this.

- Data augmentation. But be careful with large memory problem stated above. One workaround is to
use as much data as you want, but sample a proper amount of descriptors to compute the codebook.

### One Last Trick to Boost Performance - Data Augmentation

> It's ultimate, epic and hacky. I know. Call me thief and despise as much as you want. But it also has a dangerous downside: __overfitting__ may occur when performing on `test` set. Right now the best I can do is cross fingers.

The answer is simple and obvious, either use deep learning to replace these antique features or augment the training data. I choose the latter one. 
Here are the details with data augmentation:

<table class="tg">
  <tr>
    <th class="tg-baqh">Accuracy</th>
    <th class="tg-804w">lab</th>
    <th class="tg-804w">laudry</th>
    <th class="tg-804w">library</th>
    <th class="tg-804w">living room</th>
    <th class="tg-804w">lobby</th>
    <th class="tg-804w">cb_length</th>
    <th class="tg-804w">cb_des_num</th>
    <th class="tg-804w">im_num_per_cls</th>
  </tr>
  <tr>
    <td class="tg-baqh">70.5</td>
    <td class="tg-804w">60</td>
    <td class="tg-804w">55</td>
    <td class="tg-804w">90</td>
    <td class="tg-804w">63</td>
    <td class="tg-804w">85</td>
    <td class="tg-804w">1024</td>
    <td class="tg-804w">~32w</td>
    <td class="tg-804w">(120x1,200x4)</td>
  </tr>
</table>

The above scheme cannot be implemented with larger training data due to the memory problem when computing k-means in the codebook generation step. Then I sample some descriptors (parameter `numDesCb`) to do k-means and the orginal, enriched descriptors are kept still to compute the image representation. Such a tradeoff witnesses the following result:
<table class="tg">
  <tr>
    <th class="tg-baqh">Accuracy</th>
    <th class="tg-804w">lab</th>
    <th class="tg-804w">laudry</th>
    <th class="tg-804w">library</th>
    <th class="tg-804w">living room</th>
    <th class="tg-804w">lobby</th>
    <th class="tg-804w">cb_length</th>
    <th class="tg-804w">cb_des_num</th>
    <th class="tg-804w">im_num_per_cls</th>
  </tr>
  <tr>
    <td class="tg-baqh"></td>
    <td class="tg-804w"></td>
    <td class="tg-804w"></td>
    <td class="tg-804w"></td>
    <td class="tg-804w"></td>
    <td class="tg-804w"></td>
    <td class="tg-804w">1024</td>
    <td class="tg-804w"></td>
    <td class="tg-804w"><font color="green">(120x1,200x4)</font></td>
  </tr>
</table>

### Acknowledgement

This term has ended. And this one is the literally last course I ever take in my entire life. Bye bye, student life! Special thanks are given to [T. Xiao](http://www.ee.cuhk.edu.hk/~xiaotong/), [K. Kang](http://www.ee.cuhk.edu.hk/~kkang/), [Y. Xiong](http://personal.ie.cuhk.edu.hk/~xy012/) for concrete help and discussions. I cannot make this out without you guys!




