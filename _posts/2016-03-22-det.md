---
layout: post
comments: false
title:  "Pedestrian Detection 101 using HOG"
excerpt: "We implement a pedestrian detection system to solve the classical problem in computer vision. Out of date features (HOG) are used as the representation features and fed into the SVM training to obtain a detector."
date:   2016-03-22 12:00:00
mathjax: true
---

Pedestrian detection is a challenging problem in computer vision. One of the typical and effective frameworks applies histogram of gradient (HOG) as descriptor and linear SVM to train the pedestrian detector. Using HOG descriptors to represent training samples, we can train a linear detector by SVM. In detection phase, we convolve the linear detector with HOG descriptors extracted from the dense detection windows within an image, assigning detection score to each window. A threshold is enforced to decide whether a window contains a human. I implement the basic part plus the bonus modules and the detector achieves a **63.78%** average precision, which is still a toy-case benchmark. The performance breakdown of each component, in general, is summarized as follows:

> The baseline model equipped with the default settings provided in the skeleton code is __39.2__; modify the threshold on different scales, it boosts to __52.5__; change the NMS overlap, it goes to __55.76__; switch from R-HOG to C-HOG, it becomes __58.38__; if we change the NMS scheme to merge similar boxes, it downgrades to __54.48__; at last, with the default NMS setting and change the normalization to norm2_cut, the final precision becomes __63.78__.

* [Source Code]() (written in C++ and tested on Visual Studio 2010)

### Module Description

#### Linear Detector Training
Given a set of training images, we divide it into positive samples and negative samples. The positive samples are the images containing only one pedestrian, while the negative ones contain no human. We resize each sample to a fixed size, i.e. 128 x 64. This size is applied to the training samples in the implementation later. Then we extract HOG descriptor for each training sample, which is a 15 x 7 x 36 = 3,780-dim vector. All the HOG descriptors are fed into two-class linear SVM to train the human detector. The obtained detector is also a 3,780D vector. In practice, we reshape the detector to a 3D matrix, i.e. in 15 x 7 x 36, for the convenience of detection in the following step.

#### Sliding Window Strategy 
Given an image, our task is to detect the pedestrian(s) from it. Let us take a 912 x 912 grayscale image for example. 
It's divided into 113 x 113 blocks.
We can extract the HOG descriptor for each block and then form a 3D matrix in 113 x 113 x 36. 
In the above steps, we train a linear pedestrian detector in 15 x 7 x 36. Then the 15 x 7 x 36 detector is convolved on the 113 x 113 x 36 matrix, which yields central part of the convolution in 113 x 113. We enforce a threshold to select the position where the score of convolution is above the threshold as hypothesis. 
In this project, we will use the OpenCV function "filter2D" to implement the sliding window strategy.

#### Multiple Scale Manner 
In practice, the scales of human are various. However, the scale of the detector is fixed (15 x 7 x 36), which makes it difficult to detect the human on other scale, e.g. 30 x 14. For better performance, we perform detection on multiple scales of a given image. To achieve detection on multiple scales, we simply resize the image by several fixed factors, e.g. 0.21, 0.27, 0.3. The thresholds for these scales are set to 3.0, 3.5 and 4.5 respectively.


### Extra Credit

#### C-HOG

The circular HOG idea was proposed by [Dalal and Trigss]() where the block is composed of circulars instead of squares. The following digram shows a nice glimpse. Speficially, I set the cell length of the circular block the same as that of the R-HOG's, meaning the inner radius is 4 (half of the cell, 4/8) and the outer radius is 8.
<div class="imgcap">
<img src="/assets/det/hog.png">
<div class="thecap" style="text-align:justify">Rectangular vs Circular HOG.</div>
</div>

The implementation starts in line `#152` of the routine `HOGExtractor.cpp`.




#### NMS scheme
Non-maximum suppression technique is quite popular in the vision tasks where it reduces redundant detections and avoid false positives. But as for the effectiveness of it, I would say, it depends. After all, it does not alter the training process and only serves as a modification of the test results. See the ablation study part for detailed results regarding this point. 

Specifically, in each overlapped-box group, I take the first K highly-scored boxes and average them in terms of coordinates and scores. The implementation starts in line `#108` of the routine `PostProcessor.cpp`.

<div class="imgcap">
<img src="/assets/det/nms.png">
<div class="thecap" style="text-align:justify">Customized NMS scheme where the first K boxes are averaged in terms of coordinates and scores in each group. (Note that the diagram above is from the assignment specification document and takes a max-coordinate policy among boxes, which is <b>different</b> from mine. I am just too lazy to draw a new one. 
It will suffice.)</div>
</div>

#### Normalization choice

As specified in the document, I take several forms of normalization in the HOG extraction process and it turns out that L2-norm with max-value clipping works best. The implementation starts in line `#27` of the routine `HOGExtractor.cpp`.

### Tuning Parameters and Ablation Study

The following parameters are of vital importance to achieve a high performance. The first three scopes only in the testing phase where the latter two also needs re-extracting features and re-training SVM detector. They are written in the optimal form of the detector.

```python
threshold = [1.5, 2, 3]			# thres for each scale
overlap = 0.6 					# NMS overlap thres
nms_scheme = 'default'

hog_type = 'C-HOG'					# needs re-training
norm_choice = 'norm2_with_clip_0.2'			# needs re-training
```

**Threshold.** The following shows how the effect of thresholding convolution scores on the test images.
Other settings: R-HOG, NMS threshold is 0.2 as default, no other fancy stuff.
<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;border-color:#ccc;}
.tg td{font-family:Arial, sans-serif;font-size:14px;padding:5px 10px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#ccc;color:#333;background-color:#fff;}
.tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:5px 10px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#ccc;color:#333;background-color:#f0f0f0;}
.tg .tg-baqh{text-align:center;vertical-align:top}
.tg .tg-804w{font-family:Arial, Helvetica, sans-serif !important;;text-align:center;vertical-align:top}
</style>

<table class="tg">
  <tr>
    <th class="tg-baqh">Threshold</th>
    <th class="tg-804w">1, 1.5, 2</th>
    <th class="tg-804w">1.5, 2, 2.5 </th>
    <th class="tg-804w">1.5, 2, 3</th>
    <th class="tg-804w">2.0, 2.5, 3.5</th>
    <th class="tg-804w">3.0,3.5,4.5</th>
  </tr>
  <tr>
    <td class="tg-baqh">AP(%)</td>
    <td class="tg-804w">49.2</td>
    <td class="tg-804w">52.27</td>
    <td class="tg-804w"><b>52.5</b></td>
    <td class="tg-804w">46</td>
    <td class="tg-804w">39.2</td>
  </tr>
</table>

**Overlap.** I also found the threshold for NMS overlap is quite important. 
Overlap = 1 means no NMS at all. 
Other settings: R-HOG, use the optimal scale threshold as above (and thereafter also!).


<table class="tg">
  <tr>
    <th class="tg-baqh">NMS (R-HOG)</th>
    <th class="tg-804w">0.2</th>
    <th class="tg-804w">0.5 </th>
    <th class="tg-804w">0.6</th>
    <th class="tg-804w">0.7</th>
    <th class="tg-804w">0.8</th>
    <th class="tg-804w">1.0</th>
  </tr>
  <tr>
    <td class="tg-baqh">AP(%)</td>
    <td class="tg-804w">52.5</td>
    <td class="tg-804w">54.82</td>
    <td class="tg-804w">55.58</td>
    <td class="tg-804w"><b>55.76</b></td>
    <td class="tg-804w">52.63</td>
    <td class="tg-804w">33.69</td>
  </tr>
  </tr>
</table>

**C-HOG.** The optimal NMS overlap threshold changes slightly to 0.6 when I use the Circular HOG as the feature representation, shown as below. And the performance boosts about 3% when we use C-HOG, which is nice.

<table class="tg">
  <tr>
    <th class="tg-baqh">NMS (C-HOG)</th>
    <th class="tg-804w">0.5 </th>
    <th class="tg-804w">0.6</th>
    <th class="tg-804w">0.7</th>
    <th class="tg-804w">0.8</th>
  </tr>
  <tr>
    <td class="tg-baqh">AP(%)</td>
    <td class="tg-804w">56.48</td>
    <td class="tg-804w"><b>58.38</b></td>
    <td class="tg-804w">57.81</td>
    <td class="tg-804w">54.42</td>
  </tr>
  </tr>
</table>


**NMS scheme.**
The following table shows the case where the new NMS works. 'Merge_K' means how many top-score boxes are used to merge (average) the coordinates. Other settings: use C-HOG feature, L1 normalization.

<table class="tg">
  <tr>
    <th class="tg-baqh">NMS scheme</th>
    <th class="tg-804w">Default </th>
    <th class="tg-804w">Merge_2</th>
    <th class="tg-804w">Merge_4</th>
    <th class="tg-804w">Merge_8</th>
  </tr>
  <tr>
    <td class="tg-baqh">L1-norm</td>
    <td class="tg-804w">56.81</td>
    <td class="tg-804w">57.26</td>
    <td class="tg-804w"><b>58.75</b></td>
    <td class="tg-804w">55.59</td>
  </tr>
  </tr>
</table>

However, the new scheme doesn't enhance the performance when the features are normalized in a L2-norm way, as is shown below. Therefore, we don't use the new NMS scheme in the final proposal.

<table class="tg">
  <tr>
    <th class="tg-baqh">NMS scheme</th>
    <th class="tg-804w">Default </th>
    <th class="tg-804w">Merge_4</th>
    <th class="tg-804w">NMS scheme</th>
    <th class="tg-804w">Default</th>
    <th class="tg-804w">Merge_2</th>
    <th class="tg-804w">Merge_4</th>
    <th class="tg-804w">Merge_8</th>
  </tr>
  <tr>
    <td class="tg-baqh">L2-norm</td>
    <td class="tg-804w">58.38</td>
    <td class="tg-804w"><i>54.48</i></td>
    <td class="tg-804w">L2-norm_cut</td>
    <td class="tg-804w">63.78</td>
    <td class="tg-804w"><i>61.13</i></td>
    <td class="tg-804w">58.85</td>
    <td class="tg-804w">58.07</td>
  </tr>
  </tr>
</table>


**Norm choice.** Finally, I tried several normalization choices based on the C-HOG feature with the default NMS setting and found that L2 with the clipping value of 2 works best, making such a combination the final candidate.

<table class="tg">
  <tr>
    <th class="tg-baqh">Norm choice</th>
    <th class="tg-804w">L1</th>
    <th class="tg-804w">L1_sqrt</th>
    <th class="tg-804w">L2</th>
    <th class="tg-804w">L2_cut(0.1)</th>
    <th class="tg-804w">L2_cut(0.2)</th>
    <th class="tg-804w">L2_cut(0.3)</th>
  </tr>
  <tr>
    <td class="tg-baqh">AP(%)</td>
    <td class="tg-804w">56.81</td>
    <td class="tg-804w">54.76</td>
    <td class="tg-804w">58.38</td>
    <td class="tg-804w">55.66</td>
    <td class="tg-804w">63.78</td>
    <td class="tg-804w">58.68</td>
  </tr>
  </tr>
</table>

### Experiment Results
The following shows some visual examples where the algorithm can detect people from clustered background and detect multiple people.
<div class="imgcap">
<img src="/assets/det/example.png">
<div class="thecap" style="text-align:justify">Some detection visual results.</div>
</div>

Overall, our implementation achives a 63.78% AP performance. However, there are still 6 images out of the 40 validation images where the detector finds no people at all! 
<div class="imgcap">
<img src="/assets/det/failure.png">
<div class="thecap" style="text-align:justify">The left two shows two failure cases and the rightmost shows the precision-recall curve.</div>
</div>

**Failure Analysis.**
